{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymaltspro as pmp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barycenter_imputation(pmp_self, X_estimation, Y_estimation, MG):\n",
    "    Y_counterfactual = []\n",
    "    for i in X_estimation.index.values:\n",
    "        # make a holder list for adding matched units' outcomes\n",
    "        matched_unit_ids = MG.query(f'unit == {i}').query(pmp_self.treatment + ' != unit_treatment').matched_unit.values\n",
    "        matched_unit_outcomes = Y_estimation[matched_unit_ids, :]\n",
    "        y_i_counterfactual = pmp.wasserstein2_barycenter(\n",
    "            sample_array_1_through_n = matched_unit_outcomes, \n",
    "            weights = np.repeat(1/matched_unit_outcomes.shape[0], matched_unit_outcomes.shape[0]),\n",
    "            n_samples_min=pmp_self.n_samples_min\n",
    "        )\n",
    "        Y_counterfactual.append(y_i_counterfactual)\n",
    "    return np.array(Y_counterfactual)\n",
    "\n",
    "def sample_quantile(quantile_fn, quantile):\n",
    "    '''\n",
    "    description\n",
    "    -----------\n",
    "    linearly interpolate quantile function and return value of a given quantile\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    quantile_fn : numpy array with values of quantile function at specified quantiles\n",
    "    quantile : value of quantile\n",
    "    n_qtls : size of quantile function\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    quantile function evaluated at specified quantile\n",
    "    '''\n",
    "    n_qtls = quantile_fn.shape[0] - 1\n",
    "    quantile_index = quantile * n_qtls\n",
    "    quantile_floor = int(np.floor(quantile_index))\n",
    "    quantile_ceil  = int(np.ceil(quantile_index))\n",
    "    if quantile_floor == quantile_ceil == quantile_index:\n",
    "        return(quantile_fn[quantile_floor])\n",
    "    else:\n",
    "        return np.sum([quantile_fn[quantile_floor] * (quantile_index - quantile_floor), quantile_fn[quantile_ceil] * (quantile_ceil - quantile_index)])\n",
    "def ITE(pmp_self, y_true, y_impute, n_mc_samples, obs_treatment, y_true_qtl_id = False, y_impute_qtl_id = False):\n",
    "    if y_true_qtl_id == False:\n",
    "        y_true_qtl_fn = np.quantile(y_true, q = np.arange(pmp_self.n_samples_min)/pmp_self.n_samples_min)\n",
    "    else:\n",
    "        y_true_qtl_fn = y_true\n",
    "    \n",
    "    if y_impute_qtl_id == False:\n",
    "        y_impute_qtl_fn = np.quantile(y_impute, q = np.arange(pmp_self.n_samples_min)/pmp_self.n_samples_min)\n",
    "    else:\n",
    "        y_impute_qtl_fn = y_impute\n",
    "    \n",
    "    qtls_to_sample = np.random.uniform(low = 0, high = 1, size = n_mc_samples)\n",
    "    if obs_treatment == 1:\n",
    "        y_treat = np.array([sample_quantile(quantile_fn = y_true_qtl_fn, quantile = q) for q in qtls_to_sample])\n",
    "        y_control = np.array([sample_quantile(quantile_fn = y_impute_qtl_fn, quantile = q) for q in qtls_to_sample])\n",
    "    else:\n",
    "        y_treat = np.array([sample_quantile(quantile_fn = y_impute_qtl_fn, quantile = q) for q in qtls_to_sample])\n",
    "        y_control = np.array([sample_quantile(quantile_fn = y_true_qtl_fn, quantile = q) for q in qtls_to_sample])\n",
    "        \n",
    "    return (y_treat > y_control).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation Setup: multiple continuous covariates\n",
    "- for i = 1...n\n",
    "    - x_{i0},...,x_{i10} ~ Unif[0, 1]\n",
    "    - error_{a,i} ~ Normal(0, 1)\n",
    "    - error_{y, i} ~ Normal(0, 1)\n",
    "    - a_i = 1(expit(x_{i0} + x_{i1} + error_{a, i}) > 0.5)\n",
    "    - if a_i = 0\n",
    "        - y_i = Beta(sin(pi * x_{i1) * x_{i2}) + 20(x_{i3} - 0.5)^2 + 10x_{i4} + 5x_{i5} + error_{y, i}, sin(pi * x_{i1) * x_{i2}) + 20(x_{i3} - 0.5)^2 + 10x_{i4} + 5x_{i5} + error_{y, i})\n",
    "        - E[Y_i | A_i = 0] = 1/2\n",
    "    - if a_i = 1\n",
    "        - y_i = Beta(2 * (sin(pi * x_{i1) * x_{i2}) + 20(x_{i3} - 0.5)^2 + 10x_{i4} + 5x_{i5} + x_{i3}cos(pi * x_{i1} * x_{i2}) + error_{y, i}), 2 * (sin(pi * x_{i1) * x_{i2}) + 20(x_{i3} - 0.5)^2 + 10x_{i4} + 5x_{i5} + x_{i3}cos(pi * x_{i1} * x_{i2}) + error_{y, i}))\n",
    "        - E[Y_i | A_i = 1] = 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "for dataset_iteration in range(100):\n",
    "    print(dataset_iteration)\n",
    "    seed = 2020 + 1000 * dataset_iteration\n",
    "    np.random.seed(seed)\n",
    "    n_units = 1000\n",
    "    n_obs_y = 1001\n",
    "    X = np.random.uniform(low = 0, high = 1, size = [n_units, 11])\n",
    "    error_a = np.random.normal(loc = 0, scale = 1, size = n_units)\n",
    "    error_y = np.random.normal(loc = 0, scale = 1, size = n_units)\n",
    "    A = (1/(1 + np.exp(-1 * (X[:, 0] + X[:, 1] + error_a))) > 0.5).astype(int)\n",
    "    y0_param = np.sin(np.pi * X[:, 1] * X[:, 2]) + 20*(X[:, 3] - 0.5)**2 + 10*X[:, 4] + error_y**2\n",
    "    y1_param = 3 * (np.sin(np.pi * X[:, 1] * X[:, 2]) + 20*(X[:, 3] - 0.5)**2 + 10*X[:, 4] + np.cos(np.pi * X[:, 1] * X[:, 2]) + error_y**2)\n",
    "    y0 = np.array([np.random.beta(a = y0_param[i], b = y0_param[i], size = n_obs_y) for i in range(n_units)])\n",
    "    y1 = np.array([np.random.beta(a = y1_param[i], b = y1_param[i], size = n_obs_y) for i in range(n_units)])\n",
    "    y = np.array([y0[i, :] if A[i] == 0  else y1[i, :] for i in range(n_units)])\n",
    "    y_unobs = np.array([y0[i, :] if A[i] == 1  else y1[i, :] for i in range(n_units)])\n",
    "    maltspro_df = pd.DataFrame(np.hstack([X,A.reshape([n_units, 1])]), columns=list('X_' + str(i) for i in range(11)) + ['A'])\n",
    "\n",
    "    if 'dataset_' + str(seed) not in os.listdir('./experiments/cont_features/.'):\n",
    "        os.mkdir('./experiments/cont_features/dataset_' + str(seed))\n",
    "    maltspro_df.to_csv('./experiments/cont_features/dataset_' + str(seed) + '/X.csv', index = False)\n",
    "    pd.DataFrame(y).to_csv('./experiments/cont_features/dataset_' + str(seed) + '/Y.csv', index = False)\n",
    "\n",
    "        \n",
    "    # split into training and estimation datasets: 20% for training, 80% for estimation\n",
    "    train_indexes = np.random.choice(range(n_units), size = int(0.2 * n_units), replace = False)\n",
    "    est_indexes = list(set(range(n_units)) - set(train_indexes))\n",
    "    X_train = maltspro_df.iloc[train_indexes, :].reset_index()\n",
    "    X_est = maltspro_df.iloc[est_indexes, :].reset_index()\n",
    "    y_train = y[train_indexes, :]\n",
    "    y_est = y[est_indexes, :]\n",
    "    y_unobs_est = y_unobs[est_indexes, :]\n",
    "    \n",
    "    # run MALTSPro\n",
    "    maltspro = pmp.pymaltspro(X = X_train,\n",
    "                              y = y_train, \n",
    "                              treatment = 'A', \n",
    "                              discrete = [],\n",
    "                              C = 0.001,\n",
    "                              k = 10)\n",
    "\n",
    "    maltspro.fit(method = 'SLSQP')\n",
    "        \n",
    "    # save maltspro\n",
    "    pkl_file = open('./experiments/cont_features/dataset_' + str(seed) + '/malts_model.pkl', 'wb')\n",
    "    pkl.dump(maltspro, file = pkl_file)\n",
    "    \n",
    "    # get matched groups\n",
    "    mg_df = maltspro.get_matched_groups(X_estimation=X_est,\n",
    "                                        Y_estimation= y_est,\n",
    "                                        k =10)\n",
    "    \n",
    "    \n",
    "    # impute counterfactuals using barycenter of k nn\n",
    "    y_bary = barycenter_imputation(pmp_self = maltspro, \n",
    "                                   X_estimation=X_est,\n",
    "                                   Y_estimation= y_est,\n",
    "                                   MG = mg_df)\n",
    "    \n",
    "    # estimate the ITE with known counterfactuals\n",
    "    ITE_true = []\n",
    "    for i in range(len(est_indexes)):\n",
    "        ITE_true.append(\n",
    "            ITE(pmp_self = maltspro, \n",
    "                y_true = y_est[i, :],\n",
    "                y_impute = y_unobs_est[i, :],\n",
    "                n_mc_samples = 10000,\n",
    "                obs_treatment = X_est.loc[i, 'A'],\n",
    "                y_true_qtl_id = False,\n",
    "                y_impute_qtl_id = False)\n",
    "            )\n",
    "    ITE_true = np.array(ITE_true)\n",
    "    ATE_true = ITE_true.mean()\n",
    "    \n",
    "    # estimate ITE with MALTS' counterfactual \n",
    "    ITE_malts = []\n",
    "    for i in range(len(est_indexes)):\n",
    "        ITE_malts.append(\n",
    "            ITE(pmp_self = maltspro, \n",
    "                y_true = y_est[i, :],\n",
    "                y_impute = y_bary[i, :],\n",
    "                n_mc_samples = 10000,\n",
    "                obs_treatment = X_est.loc[i, 'A'],\n",
    "                y_true_qtl_id = False,\n",
    "                y_impute_qtl_id = False)\n",
    "            )\n",
    "    ITE_malts = np.array(ITE_malts)\n",
    "    ATE_malts = ITE_malts.mean()\n",
    "    \n",
    "    ITE_df = pd.DataFrame({'ITE_true' : ITE_true, 'ITE_malts' : ITE_malts})\n",
    "    ITE_df.to_csv('./experiments/cont_features/dataset_' + str(seed) + '/ITE.csv', index = False)\n",
    "    \n",
    "    # delete objects locally\n",
    "    del(seed)\n",
    "    del(n_units)\n",
    "    del(n_obs_y)\n",
    "    del(X)\n",
    "    del(error_a)\n",
    "    del(error_y)\n",
    "    del(A)\n",
    "    del(y0_param)\n",
    "    del(y1_param)\n",
    "    del(y0)\n",
    "    del(y1)\n",
    "    del(y)\n",
    "    del(y_unobs)\n",
    "    del(train_indexes)\n",
    "    del(est_indexes)\n",
    "    del(X_train)\n",
    "    del(X_est)\n",
    "    del(y_train)\n",
    "    del(y_est)\n",
    "    del(y_unobs_est)\n",
    "    del(maltspro)\n",
    "    del(y_bary)\n",
    "    del(ITE_malts)\n",
    "    del(ITE_true)\n",
    "    del(ATE_malts)\n",
    "    del(ATE_true)\n",
    "    del(ITE_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del(                          )\n",
    "del(                          )\n",
    "del(                          )\n",
    "del(                          )\n",
    "del(                          )\n",
    "del()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
